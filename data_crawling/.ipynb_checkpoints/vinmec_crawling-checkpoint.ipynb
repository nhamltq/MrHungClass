{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "url =  'https://www.vinmec.com/vi/tin-tuc/hoi-dap-bac-si/?page=5'\n",
    "page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "web_url = []\n",
    "image_url = []\n",
    "for i in tqdm(range(1,563)):\n",
    "  url =  f'https://www.vinmec.com/vi/tin-tuc/hoi-dap-bac-si/?page={i}'\n",
    "  page = urllib.request.urlopen(url)\n",
    "  soup = BeautifulSoup(page, 'html.parser')\n",
    "  content = (soup.find_all(\"div\",class_ = \"post-list\")[0]).find_all(\"a\")\n",
    "  for web_url_raw in content:\n",
    "    web_url.append(web_url_raw.get(\"href\")) if web_url_raw.get(\"href\") is not None else web_url.append(\"\")\n",
    "    img_tag = web_url_raw.find(\"img\")\n",
    "    image_url.append(web_url_raw.find(\"img\").get(\"src\")) if img_tag is not None else image_url.append(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af74334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "def data_clean_in_vinmect_web(url):\n",
    "  page = urllib.request.urlopen(url)\n",
    "  soup = BeautifulSoup(page, 'html.parser')\n",
    "  new_feed = soup.find_all(\"div\",class_ = \"rich-text\")\n",
    "  search  = re.search(\"</b></p><p><i>([\\w+\\W+]+)</i></p><p><b>\",str(new_feed[0]))\n",
    "\n",
    "  question = search.groups()[0]\n",
    "  question = re.sub(\"</i></p><p><i>|</i><b><i>|</i></b><i>|</p><p><i>|</i></p><p><b>|</i> <b><i>\",'',question)\n",
    "  all_link = re.search(\"Trả lời</b></p><p>(.+)</p><p>\",str(new_feed[0]))\n",
    "  anwer = all_link.groups()[0]\n",
    "  regex_pattern = r'<a href|<a>|><b>|</b></a>'\n",
    "\n",
    "  # Split the original string based on the pattern\n",
    "  split_string = re.split(regex_pattern, anwer)\n",
    "  split_string_copy = split_string\n",
    "  links = []\n",
    "  for idx,string in enumerate(split_string):\n",
    "    if '=\"https:' in string:\n",
    "      split_string_copy[idx] = \"[link]\"\n",
    "      links.append(re.sub('=|\"','',string))\n",
    "  response = ''.join(split_string_copy)\n",
    "  answer = re.sub(\"</p><p>| &gt;|<b>|</b>\",'',response)\n",
    "  return question,answer,links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "data2 = pd.read_csv(\"vinmect_url.csv\")\n",
    "datax  = pd.DataFrame({\"urls\":[None]*5065,\"image_title\":[None]*5065,\"question\":[None]*5065,\"answer\":[None]*5065,\"img_link\":[None]*5065})\n",
    "\n",
    "for i in tqdm(range(3248,5056)):\n",
    "  url = \"https://www.vinmec.com/vi\"+data2['url'][i]\n",
    "  try:\n",
    "    question,answer,links = data_clean_in_vinmect_web(url)\n",
    "  except:\n",
    "    question,answer,links = [\"\",\"\",\"\"]\n",
    "  datax.iloc[i,:] = [data2.iloc[i,0],data2.iloc[i,1],question,answer,links]\n",
    "  datax.to_csv(\"vinmect_crawling.csv\",index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6c819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
